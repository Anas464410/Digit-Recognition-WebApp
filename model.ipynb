{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e54c12a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Flatten,BatchNormalization\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d669da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mnist dataset\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8f8c85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of x_train (60000, 28, 28)\n",
      "Dimension of x_test (10000, 28, 28)\n",
      "Dimension of y_test (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Print the dimensions of the dataset\n",
    "\n",
    "print(\"Dimension of x_train\",x_train.shape)\n",
    "print(\"Dimension of x_test\",x_test.shape)\n",
    "print(\"Dimension of y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b40e66c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#we will see a single image in out dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[5])\n",
    "plt.show()\n",
    "print(y_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3028d480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some parameters for the model\n",
    "\n",
    "num_classes = 10\n",
    "#as we have 10 classes (0-9) \n",
    "#we need to prdeict one out of 10 which has high probability\n",
    "epochs = 30\n",
    "batch_size = 128\n",
    "img_rows = 28 \n",
    "img_cols = 28\n",
    "#as each image is 28 by 28 pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5d7a749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing image \n",
    "x_train =x_train.astype(float)\n",
    "x_train =x_train/255\n",
    "x_test =x_test.astype(float)\n",
    "x_test =x_test/255\n",
    "#y_train =y_train/255\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, num_classes = 10, dtype = 'float32')\n",
    "y_test = to_categorical(y_test, num_classes = 10, dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "674bf2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#format in which image are feed to our model \n",
    "#there are two cases possible either we can have channel first than image dimension\n",
    "#or we can have dimension first than channel \n",
    "#we have one channel as it is a grey scale image therfore '1'\n",
    "if K.image_data_format() =='channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0],1,img_rows,img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0],1,img_rows,img_cols)\n",
    "    input_shape = (1,img_rows,img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0],img_rows,img_cols,1)\n",
    "    x_test = x_test.reshape(x_test.shape[0],img_rows,img_cols,1)\n",
    "    input_shape = (img_rows,img_cols,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77ef4dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build our model\n",
    "#BY DEFAULT STRIDE IS 1\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = input_shape))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d07307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile our model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ef86303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 11, 11, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 11, 11, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 6, 6, 32)          25632     \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 6, 6, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 6, 6, 32)          0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 4, 4, 64)          18496     \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 4, 4, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 2, 2, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 2, 2, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 1, 1, 64)          102464    \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 1, 1, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 1, 1, 64)          0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 194,762\n",
      "Trainable params: 194,250\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf1c17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "469/469 [==============================] - 48s 98ms/step - loss: 0.3748 - accuracy: 0.8922 - val_loss: 0.0853 - val_accuracy: 0.9752\n",
      "Epoch 2/30\n",
      "469/469 [==============================] - 48s 102ms/step - loss: 0.1028 - accuracy: 0.9724 - val_loss: 0.0615 - val_accuracy: 0.9788\n",
      "Epoch 3/30\n",
      "119/469 [======>.......................] - ETA: 34s - loss: 0.0748 - accuracy: 0.9812"
     ]
    }
   ],
   "source": [
    "#fit the model\n",
    "model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cafe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "score ,acc = model.evaluate(x_test,y_test)\n",
    "print(\"Score is :\",score)\n",
    "print(\"Accuracy :\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d99fd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save our model\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"models.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4621f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs\n",
    "tfjs.converters.save_keras_model(model,'models/model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
